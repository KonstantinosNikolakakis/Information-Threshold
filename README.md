# Information-Threshold

Efficient learning of hidden tree-structures from noisy data. Model: Tree-structured Markov Random Fields.

Last revision: Feb 2021 (Matlab R2019b) Author: Konstantinos Nikolakakis

The purpose of this code is to support the paper: "Optimal Rates for Learning Hidden Tree Structures" by Konstantinos E. Nikolakakis, Dionysios S. Kalogerias, Anand D. Sarwate.

Any part of this code used in your work should cite the above publication. This code is provided "as is" to support the ideals of reproducible research. Any issues with this code should be reported by email to k.nikolakakis@rutgers.edu.

The code is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License available at https://creativecommons.org/licenses/by-nc-sa/4.0/.

Description: Structure_Learning.m generates a tree-structured (over p nodes with binary values) and synthetic samples based on that model. Structure estimation is performed on the noiseless and noisy data of the underlying model. Noise is generated by a binary symmetric channel. We estimate the hidden structure by coinsidering the Chow-Liu algorithm. Our goal is to graphical illustrate the decay of error-rate (probability of missing at least one edge of the tree) for different values of the information threshold. The exponential decay of the error-rate when the information treshold increases supports the theoretical results of the paper. 
